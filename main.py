from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import uvicorn
from datetime import datetime

from services.prediction_service import PredictionService
from models.rare_model import RAREModel
from data.curriculum_loader import CurriculumLoader
from config.settings import settings

# FastAPI uygulamasÄ±
app = FastAPI(
    title="LGS Din KÃ¼ltÃ¼rÃ¼ Soru Tahmin Sistemi",
    description="RARE mimarisi kullanarak LGS Din KÃ¼ltÃ¼rÃ¼ sorularÄ±nÄ± tahmin eden sistem",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global servis instance'larÄ±
prediction_service = PredictionService()
rare_model = RAREModel()
curriculum_loader = CurriculumLoader()

# Pydantic modelleri
class PredictionRequest(BaseModel):
    exam_date: Optional[str] = None
    question_count: int = 20
    difficulty_filter: Optional[str] = None
    topic_filter: Optional[str] = None

class TopicAnalysisRequest(BaseModel):
    topic: str
    depth: int = 2

class QuestionGenerationRequest(BaseModel):
    topic: str
    count: int = 5
    difficulty: Optional[str] = None

# API Endpoints
@app.get("/")
async def root():
    """Ana endpoint - sistem bilgileri"""
    return {
        "message": "LGS Din KÃ¼ltÃ¼rÃ¼ Soru Tahmin Sistemi",
        "version": "1.0.0",
        "architecture": "RARE (Retrieval-Augmented Reasoning Engine)",
        "features": ["RAG", "CAG Cache", "Gemini Reasoning"],
        "timestamp": datetime.now().isoformat()
    }

@app.post("/predict/exam-questions")
async def predict_exam_questions(request: PredictionRequest):
    """SÄ±nav sorularÄ± tahmin et"""
    try:
        result = prediction_service.predict_next_exam_questions(
            exam_date=request.exam_date,
            question_count=request.question_count,
            difficulty_filter=request.difficulty_filter,
            topic_filter=request.topic_filter
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/topic")
async def analyze_topic(request: TopicAnalysisRequest):
    """Belirli bir konuyu detaylÄ± analiz et"""
    try:
        result = prediction_service.get_topic_specific_prediction(
            topic=request.topic,
            depth=request.depth
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate/questions")
async def generate_questions(request: QuestionGenerationRequest):
    """Belirli bir konu iÃ§in soru Ã¼ret"""
    try:
        context = rare_model.rag_system.get_context_for_query(request.topic, request.topic)
        result = rare_model.gemini_service.generate_questions_with_reasoning(
            context=context,
            topic=request.topic,
            count=request.count
        )
        
        # Zorluk filtresi uygula
        if request.difficulty and 'questions' in result:
            filtered_questions = [
                q for q in result['questions'] 
                if q.get('difficulty') == request.difficulty
            ]
            result['questions'] = filtered_questions
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/curriculum/topics")
async def get_curriculum_topics():
    """MÃ¼fredat konularÄ±nÄ± listele"""
    try:
        curriculum_data = curriculum_loader.load_din_kulturu_curriculum()
        topics = {}
        
        for doc in curriculum_data:
            topic = doc['topic']
            if topic not in topics:
                topics[topic] = []
            topics[topic].append({
                'subtopic': doc['subtopic'],
                'difficulty': doc['difficulty'],
                'keywords': doc.get('keywords', [])
            })
        
        return {
            "topics": topics,
            "total_topics": len(topics),
            "total_subtopics": len(curriculum_data)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/curriculum/search")
async def search_curriculum(query: str, topic: Optional[str] = None):
    """MÃ¼fredat iÃ§inde arama yap"""
    try:
        relevant_docs = rare_model.rag_system.search_relevant_documents(
            query=query,
            filters={'topic': topic} if topic else None
        )
        
        return {
            "query": query,
            "topic_filter": topic,
            "results": relevant_docs,
            "result_count": len(relevant_docs)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analysis/curriculum-trends")
async def analyze_curriculum_trends():
    """MÃ¼fredat trendlerini analiz et"""
    try:
        analysis = rare_model.analyze_curriculum_trends()
        return analysis
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/reasoning/deep-analysis")
async def deep_reasoning_analysis(topic: str, depth: int = 3):
    """Derin reasoning analizi yap"""
    try:
        result = rare_model.deep_reasoning(topic, depth)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/cache/clear")
async def clear_cache(pattern: str = "*"):
    """Cache'i temizle"""
    try:
        rare_model.cache.clear_cache(pattern)
        return {"message": f"Cache cleared with pattern: {pattern}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/system/health")
async def health_check():
    """Sistem saÄŸlÄ±k kontrolÃ¼"""
    try:
        # Redis baÄŸlantÄ±sÄ± kontrol et
        redis_status = "healthy"
        try:
            rare_model.cache.redis_client.ping()
        except:
            redis_status = "error"
        
        # ChromaDB kontrol et
        chroma_status = "healthy"
        try:
            rare_model.rag_system.collection.count()
        except:
            chroma_status = "error"
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "components": {
                "redis_cache": redis_status,
                "chroma_db": chroma_status,
                "gemini_api": "healthy" if settings.GOOGLE_API_KEY else "not_configured"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/system/stats")
async def system_stats():
    """Sistem istatistikleri"""
    try:
        # ChromaDB dokÃ¼man sayÄ±sÄ±
        doc_count = rare_model.rag_system.collection.count()
        
        # MÃ¼fredat konularÄ±
        curriculum_data = curriculum_loader.load_din_kulturu_curriculum()
        topic_counts = {}
        for doc in curriculum_data:
            topic = doc['topic']
            topic_counts[topic] = topic_counts.get(topic, 0) + 1
        
        return {
            "database_stats": {
                "total_documents": doc_count,
                "curriculum_topics": len(topic_counts),
                "topic_distribution": topic_counts
            },
            "system_config": {
                "embedding_model": settings.EMBEDDING_MODEL,
                "gemini_model": settings.GEMINI_MODEL,
                "cache_ttl": settings.CACHE_TTL,
                "top_k_documents": settings.TOP_K_DOCUMENTS
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# CLI FonksiyonlarÄ±
class CLIInterface:
    def __init__(self):
        self.prediction_service = PredictionService()
        self.rare_model = RAREModel()
    
    def interactive_prediction(self):
        """EtkileÅŸimli tahmin modu"""
        print("ðŸŽ¯ LGS Din KÃ¼ltÃ¼rÃ¼ Soru Tahmin Sistemi")
        print("=" * 50)
        
        while True:
            print("\nSeÃ§enekler:")
            print("1. SÄ±nav sorularÄ± tahmin et")
            print("2. Konu analizi yap")
            print("3. Soru Ã¼ret")
            print("4. MÃ¼fredat ara")
            print("5. Ã‡Ä±kÄ±ÅŸ")
            
            choice = input("\nSeÃ§iminizi yapÄ±n (1-5): ")
            
            if choice == "1":
                self._predict_questions_cli()
            elif choice == "2":
                self._analyze_topic_cli()
            elif choice == "3":
                self._generate_questions_cli()
            elif choice == "4":
                self._search_curriculum_cli()
            elif choice == "5":
                print("HoÅŸÃ§a kalÄ±n! ðŸ‘‹")
                break
            else:
                print("GeÃ§ersiz seÃ§im. LÃ¼tfen 1-5 arasÄ±nda bir sayÄ± girin.")
    
    def _predict_questions_cli(self):
        """CLI Ã¼zerinden soru tahmini"""
        print("\nðŸ“ SÄ±nav SorularÄ± Tahmini")
        print("-" * 30)
        
        count = int(input("KaÃ§ soru tahmin edilsin? (varsayÄ±lan: 10): ") or 10)
        difficulty = input("Zorluk seviyesi (kolay/orta/zor, boÅŸ bÄ±rakÄ±labilir): ") or None
        topic = input("Konu filtresi (boÅŸ bÄ±rakÄ±labilir): ") or None
        
        print("\nâ³ Tahmin yapÄ±lÄ±yor...")
        
        result = self.prediction_service.predict_next_exam_questions(
            question_count=count,
            difficulty_filter=difficulty,
            topic_filter=topic
        )
        
        print(f"\nâœ… {len(result['predicted_questions'])} soru tahmin edildi:")
        print("-" * 50)
        
        for i, question in enumerate(result['predicted_questions'][:5], 1):
            print(f"\n{i}. {question['question']}")
            for option, text in question['options'].items():
                print(f"   {option}) {text}")
            print(f"   DoÄŸru Cevap: {question['correct_answer']}")
            print(f"   Konu: {question.get('topic', 'BelirtilmemiÅŸ')}")
            print(f"   Zorluk: {question.get('difficulty', 'orta')}")
            print(f"   GÃ¼ven Skoru: {question.get('prediction_confidence', 0):.2f}")
        
        if len(result['predicted_questions']) > 5:
            print(f"\n... ve {len(result['predicted_questions']) - 5} soru daha.")
    
    def _analyze_topic_cli(self):
        """CLI Ã¼zerinden konu analizi"""
        print("\nðŸ” Konu Analizi")
        print("-" * 20)
        
        topic = input("Analiz edilecek konu: ")
        depth = int(input("Analiz derinliÄŸi (1-5, varsayÄ±lan: 2): ") or 2)
        
        print(f"\nâ³ {topic} konusu analiz ediliyor...")
        
        result = self.prediction_service.get_topic_specific_prediction(topic, depth)
        
        print(f"\nâœ… {topic} Analiz SonuÃ§larÄ±:")
        print("-" * 40)
        
        if 'deep_analysis' in result:
            insights = result['deep_analysis'].get('final_insights', {})
            if isinstance(insights, dict) and 'insights' in insights:
                print(f"ðŸ’¡ Ana Bulgular: {insights['insights'][:200]}...")
        
        if 'generated_questions' in result and 'questions' in result['generated_questions']:
            questions = result['generated_questions']['questions']
            print(f"\nðŸ“ Ãœretilen sorular ({len(questions)} adet):")
            for i, q in enumerate(questions[:3], 1):
                print(f"\n{i}. {q['question']}")
                print(f"   DoÄŸru Cevap: {q['correct_answer']}")
    
    def _generate_questions_cli(self):
        """CLI Ã¼zerinden soru Ã¼retimi"""
        print("\nðŸŽ² Soru Ãœretimi")
        print("-" * 18)
        
        topic = input("Konu: ")
        count = int(input("KaÃ§ soru? (varsayÄ±lan: 5): ") or 5)
        
        print(f"\nâ³ {topic} konusunda {count} soru Ã¼retiliyor...")
        
        context = self.rare_model.rag_system.get_context_for_query(topic, topic)
        result = self.rare_model.gemini_service.generate_questions_with_reasoning(
            context, topic, count
        )
        
        if 'questions' in result:
            print(f"\nâœ… Ãœretilen Sorular:")
            print("-" * 30)
            
            for i, question in enumerate(result['questions'], 1):
                print(f"\n{i}. {question['question']}")
                for option, text in question['options'].items():
                    print(f"   {option}) {text}")
                print(f"   DoÄŸru Cevap: {question['correct_answer']}")
                if 'reasoning' in question:
                    print(f"   AÃ§Ä±klama: {question['reasoning'][:100]}...")
    
    def _search_curriculum_cli(self):
        """CLI Ã¼zerinden mÃ¼fredat arama"""
        print("\nðŸ”Ž MÃ¼fredat Arama")
        print("-" * 20)
        
        query = input("Arama sorgusu: ")
        
        print(f"\nâ³ '{query}' aranÄ±yor...")
        
        results = self.rare_model.rag_system.search_relevant_documents(query)
        
        print(f"\nâœ… {len(results)} sonuÃ§ bulundu:")
        print("-" * 30)
        
        for i, doc in enumerate(results[:3], 1):
            print(f"\n{i}. Konu: {doc['metadata'].get('topic', 'Bilinmeyen')}")
            print(f"   Alt Konu: {doc['metadata'].get('subtopic', 'Bilinmeyen')}")
            print(f"   Ä°Ã§erik: {doc['content'][:150]}...")
            print(f"   Benzerlik: {1 - doc['distance']:.3f}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "cli":
        # CLI modu
        cli = CLIInterface()
        cli.interactive_prediction()
    else:
        # Web server modu
        print("ðŸš€ LGS Din KÃ¼ltÃ¼rÃ¼ Soru Tahmin Sistemi baÅŸlatÄ±lÄ±yor...")
        print(f"ðŸ“¡ API: http://localhost:8000")
        print(f"ðŸ“– DokÃ¼mantasyon: http://localhost:8000/docs")
        
        uvicorn.run(
            "main:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
            log_level="info"
        )